# NLP学习知识点

- 什么是自然语言处理？其主要有哪些应用？能够处理什么样的问题？
- 什么是机器翻译？了解统计机器翻译与神经机器翻译大致原理？
- 什么是数据语料？数据语料主要有哪些获取途径与方法？
- 机器翻译使用的训练语料大体是哪些形式的？什么是源语言和目标语言？
- 什么是数据清洗？数据清洗的主要目的是什么？有哪些常用的处理手段？
- 在数据清洗的过程中什么是长度比过滤？为什么要进行长度比过滤？
- 什么是分词？分词的主要作用是什么？
- 什么是子词切分？为什么要进行子词切分操作？
- 什么是BLEU值？BLEU值的具体作用是什么？


# NLP基础知识

## NLP

>什么是自然语言处理？其主要有哪些应用？能够处理什么样的问题？

自然语言处理,是人与机器之间沟通的桥梁.

两个核心任务:NLU(自然语言理解)与NLG(自然语言生成)

典型应用:情感分析,聊天机器人,智能客服,机器翻译

## 机器翻译

>什么是机器翻译？了解统计机器翻译与神经机器翻译大致原理？

机器翻译又称为自动翻译，是利用计算机将一种自然语言(源语言)转换成另外一种自然(目标语言)语言的过程，本质问题是如何实现两种不同语言之间的等价转换。

统计机器翻译(SMT)的基本思想是通过**对大量的平行语料进行统计分析，构建统计翻译模型**，进而使用此模型进行翻译。从早期基于词的机器翻译已经过渡到基于短语的翻译，并正在融合句法信息，以进一步提高翻译的精确性。

神经机器翻译(NMT),它基本的建模框架是端到端序列生成模型，是将输入序列变换到输出序列的一种框架和方法。

其核心部分有两点，一是如何表征输入序列（编码），二是如何获得输出序列（解码）。

对于机器翻译而言不仅包括了编码和解码两个部分，还引入了额外的机制——注意力机制，来帮助我们进行调序。

对比:
神经机器翻译模型不需要词对齐步骤,基于注意力机制就可以动态获得词对齐信息,但是相对统计机器翻译来说,包含信息少,对齐效果弱.

神经机器翻译相对流利,但是忠实度上稍差.

改善神经机器翻译的核心:注意力机制

## 数据语料

>什么是数据语料？数据语料主要有哪些获取途径与方法？

语料库是以电子计算机为载体承载语言知识的基础资源；真实语料需要经过加工（分析和处理），才能成为有用的资源。

获取途径和方法

- 爬虫

最好的方法就是自己写爬虫，优点是可以自由的定制想要的数据，缺点是周期较长。

- 数据平台

国内一些机构贡献了一些数据集出来，大家可以在上面下载。

- 数据堂

- 搜狗实验室

- 自然语言处理与信息检索共享平台

- 聚数力

## 训练语料

>机器翻译使用的训练语料大体是哪些形式的？什么是源语言和目标语言？

输入为源语言,输出为目标语言,这被称为端到端模型

## 分词

> 什么是分词？分词的主要作用是什么？

分词就是将句子,段落,文章这种长文本,分解为以字词为单位的数据结构,方便后续的处理分析工作.本质是非结构化数据转化成结构化数据.

'词'这个粒度相对更适合分析

深度学习中部分任务也可以分'字'

三种分词的方式:

1. 基于词典匹配
2. 基于统计
3. 基于深度学习

### 基于词典匹配的分词方式

优点：速度快、成本低

缺点：适应性不强，不同领域效果差异大

基本思想是基于词典匹配，将待分词的中文文本根据一定规则切分和调整，然后跟词典中的词语进行匹配，匹配成功则按照词典的词分词，匹配失败通过调整或者重新选择，如此反复循环即可。代表方法有基于正向最大匹配和基于逆向最大匹配及双向匹配法。

### 基于统计的分词方法

优点：适应性较强

缺点：成本较高，速度较慢

这类目前常用的是算法是 HMM、CRF、SVM、深度学习 等算法，比如stanford、Hanlp分词工具是基于CRF算法。以CRF为例，基本思路是对汉字进行标注训练，不仅考虑了词语出现的频率，还考虑上下文，具备较好的学习能力，因此其对歧义词和未登录词的识别都具有良好的效果。

### 基于深度学习

优点：准确率高、适应性强

缺点：成本高，速度慢

例如有人员尝试使用双向LSTM+CRF实现分词器，其本质上是序列标注，所以有通用性，命名实体识别等都可以使用该模型，据报道其分词器字符准确率可高达97.5%。

常见的分词器都是使用机器学习算法和词典相结合，一方面能够提高分词准确率，另一方面能够改善领域适应性。

## 数据清洗

> 什么是数据清洗？数据清洗的主要目的是什么？有哪些常用的处理手段？

在对文本进行分析时，对不符合要求的数据进行处理。常见有几种：

（1）数据重复处理

（2）数据错误处理

（3）数据缺失处理

（4）数据异常处理

数据清洗过程包括遗漏数据处理，噪声数据处理，以及不一致数据处理

(一)   手工实现,通过人工检查,只要投入足够的人力物力财力,也能发现所有错误,但效率低下。在大数据量的情况下,几乎是不可能的。

(二)  通过专门编写的应用程序,这种方法能解决某个特定的问题,但不够灵活,特别是在清理过程需要反复进行(一般来说,数据清理一遍就达到要求的很少)时,导致程序复杂,清理过程变化时,工作量大。而且这种方法也没有充分利用目前数据库提供的强大数据处理能力 。

(三) 解决某类特定应用域的问题,如根据概率统计学原理查找数值异常的记录,对姓名、地址、邮政编码等进行清理,这是目前研究得较多的领域,也是应用最成功的一类。如商用系统: Trillinm Software , System Match Maketr 等。

(四)   与特定应用领域无关的数据清理,这一部分的研究主要集中在清理重复的记录上,如Data Cleanser， Data Blade Module ，Integrity 系统等。

分箱法或者回归法

## 子词切分

>什么是子词切分？为什么要进行子词切分操作？

### BPE 算法

分词主要的作用是缩小词典的长度,词典长度过长会导致在训练的过程中消耗大量的算力.我们将一些词继续细分,使得词典长度缩小.然后再采用BPE算法对未登录词进行处理.

这样我们通过BPE得到了更加合适的词表了，这个词表可能会出现一些不是单词的组合，但是这个本身是有意义的一种形式，加速NLP的学习，提升不同词之间的语义的区分度。
BPE在欧洲语系可能表现的更为有效一些，主要由于欧洲语系中存在词缀等概念。

## BLEU

>什么是BLEU值？BLEU值的具体作用是什么？

BLEU(bilingual evaluation understudy)双语互译质量辅助工具,本质上讲BLEU 就是用来衡量机器翻译文本与参考文本之间的相似程度的指标,
