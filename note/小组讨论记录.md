# 小组讨论记录

## 1-9

  关于昨天讨论的问题：最终神经机器翻译模型译文效果评测的问题，我有几点建议，大家后续可以一起思考是否合理：
  
  （1）利用标签保留准确率，召回率，F1值等指标，用来评测句子标签保留情况，我们可以对测试集中单条源语句子中的标签数量进行统计  并测算其源语中的标签在其译文结果中是否存在对应标签内容  测算当前句子的标签保留准确率 同时可以利用类似方法估计整个测试集的准确率 召回率  F1值等指标 
  
  （2）利用BLEU值进行估计，我想  BLEU是能够作为一个评测指标，因为一条标签成功保留的译文结果生成的BLEU值一定要比标签翻译成为乱码的BLEU值结果要高  这应该作为一条评测指标
  
  （3）人工限制评测条件  可以手动简直针对某个词条的上下文结果  估算其周围的标签结果是否予以保留  另外  还可以根据指定标签  估算其在指定词汇上下文中出现时候的标签保留情况  该条内容可以作为标签位置信息保留准确性的一条估算指标
// 构造数据的好处
// 为什么 测试方法  管用


//  bleu值  准确率 召回率  F1值  人工
// 标准脚本   根据每个数据集测出的数据
// moses  bleu值

//   fairseq 脚本 cpu
// 自动化训练  测试 脚本

// genate  可以修改  预处理这一步 集成自己的方法或者自己的参数  子词切分
  
// train 改不了
// fairseq  参数 用官方参数  那种训练方式好用 
// 封装成一个shell 脚本   预处理脚本  训练部分

// 训练集 是否保存标签
// 参数设置为 和 测试集一致

//  测试部分写完
//  优先poster


  

预处理1 -> 预处理2 -> 训练  -> 生成  -> 评估

预处理1 : 分词 , 转小写 , 连续空白??        基本已经完成

预处理2 : 此处较复杂, 子词切分(subword_nmt) + fairseq preprocess

训练 : fairseq train  但是例子上给了多个不同的模型,不知道要用哪个 

生成 :  fairseq optimize-fconv (可选??)  和 fairseq generate-lines 

评估 : 基本已经完成 


训练:
```bash
# Fully convolutional sequence-to-sequence model
mkdir -p $TRAIN/fconv
fairseq train -sourcelang en -targetlang zh -datadir $DATADIR \
    -model fconv -nenclayer 4 -nlayer 3 -batchsize 16 -dropout 0.2 -optim nag -lr 0.25 -clip 0.1 \
    -momentum 0.99 -timeavg -bptt 0 -savedir $TRAIN/fconv

# Standard bi-directional LSTM model
mkdir -p $TRAIN/blstm
fairseq train -sourcelang en -targetlang zh -datadir $DATADIR \
    -model blstm -nhid 512 -dropout 0.2 -dropout_hid 0 -optim adam -lr 0.0003125 \
    -savedir $TRAIN/blstm

```


生成: 
```bash
fairseq optimize-fconv 
                 -input_model $TRAIN/fconv/model_best.th7 
                 -output_model $TRAIN/fconv/model_best_opt.th7

fairseq generate -path $TRAIN/fconv/model_best_opt.th7 
                 -datadir $DATADIR 
                 -beam 10 
                 -nbest 2 
                 -dataset test 
                 -sourcelang en 
                 -targetlang zh 
                 | tee $OUTPUT.tmp
```

首先来说    poster  格式不错   
1.  第一块 介绍 有点少   丰富一些     √
2.  第二节 标题  data set 不行  要写 构造数据集的方法 √ 
     2.1 综述     
          数据集比较少 量化  (具体的数值10万) √
          L1 L2 写反了  √
          添加一个表格 单单说标签  三类  都要  列举标签  句子中间 单独出现的标签   √
          减少模棱两可的词汇
          双语数据集 wmt2018 (在2.1说明源语和目标语 以及数据量 )  √
          词对齐信息 √
      2.4 不要用这么多overview  
          把词对齐信息写明白  √
      2.5 以后再说
3.   第三节
写明白为啥要用 √
丰富内容



总结成果

完成了 三种泛化,并且集成到了脚本中

发现问题: 数据集会导致 pynlpir崩溃  已找到方法处理,正在逐步优化提高性能,

想要抽离成预处理的方式

模型是transformaer

main.sh命名  Niutrans.带标签机器翻译  名字可以长一点

路径设计成参数的形式

参数设计好一些

设计程序之前   把设计思路写清楚  让别人用起来,

数据集放在哪个目录  代码在哪个目录 程序入口

尽量不要在程序里写那么多写死的东西  尽量不要让程序有所变动,尤其是超参数

每次不同运行环境下不一样,  从外部不能动

基本不动的可以写死

把各部分统一起来

数据处理部分 -> 训练部分 -> 测试部分

参数部分 统一在这部分    如果有必要改参数则统一改

提高可用性

尽量代码简洁 用目前比较规范的 结巴分词 稳定而且高效 大体的架构 让别人用起来舒服

主函数里

for l in $src $tgt; do
    awk '{if (NR%23 == 0)  print $0; }' $tmp/train.tags.$l > $tmp/valid.$l
    awk '{if (NR%23 != 0)  print $0; }' $tmp/train.tags.$l > $tmp/train.$l
done
