这个提案包含了我对在寒假实习期间的项目介绍、解决方案、方法评估、时间规划以及个人目标。

NMT使用基于神经网络的技术来实现更多上下文精确的翻译，而不是一次翻译一个单词的破碎句子。使用大型人工神经网络计算单词序列的概率，NMT将完整的句子放入一个集成模型中。
面对全球化的趋势,很多网站为了扩展国际市场,需要将自己的网页翻译成外文版.基于这种情况,翻译公司就有了对html文本进行机器翻译的需求.然而实际上,翻译公司在面对网页源码时,也往往借助机器翻译系统作为辅助程序,再结合人工修改,以达到翻译网页的效果.
虽然神经机器学习翻译普通文本时,展现了良好的效果,但是在面对一些带标签的句子(例如html文本)时,还是会出现很多问题.比如谷歌翻译存在标签错位的问题，有道翻译存在标签缺失的问题.其实还有可能存在将标签内容本身仿作文本翻译的情况.这些问题都会导致最后产生的网页错误显示.事实上,我们绝对不能对标签进行翻译,而是要保留标签的内容和位置，然后将剩下的文本进行翻译,以保证翻译后的html仍然能够展示正确的网页.
综上所述,本系统目标是做到一段HTML代码翻译后,不需要修改或者仅需要少量的人工修改就可以展示正确的网页.

我们决定以facebook开源的fairseq框架作为基础,通过给HTML中的标签打记号的形式,训练出模型,使它能够记忆标签位置,并且能够保留标签,同时将对应位置的译文进行替换.
然后采用此模型去翻译带标签的文本,记录下评估结果.然后尝试不同种类的标记方式,对比得到效果最好的模型.

此外,我们还将大量测试谷歌翻译,通过观察一些带标签句子的翻译结果来获得启示,然后去改进我们的系统.


HTML中有一些标签,比如’加粗’,常常插入到文本之中,而翻译的时候应当忽略它们,将两侧的句子合并起来翻译.但是对于另一些标签比如’段落’等,就需要将其内部的文本看做是整体.这种情况就导致翻译上的困难.
标签的多样性.HTML中有非常多的标签类别,而且标签本身往往还带有一些其他附加信息,比如'<a>'表示的超链接等.此外,由于标签既有成对出现的,也有独自出现的,这就大大增加了标签的多样程度.
标签的随机性.正如我们无法预测用户输入一样,我们也无法预测HTML标签出现的可能性.事实上,HTML语法非常灵活,而且可能还存在大量的嵌套关系,这也给翻译带来了比较大的困难.
另外,考虑到实验室的服务器资源相对缺乏,而这个项目又需要多种方法测试,对比.所以很难在短时间内训练出相对完善的模型.

我们项目的本质就是尝试多种标签处理方法,找到效果最好的一种,并生成模型.下面是我们打算采取的几种方法.
Baseline-首先我们会训练一个baseline,即不对标签做任何特殊处理,直接用现有的模型尝试翻译.在这个baseline中我们也会做一些对比试验.主要分为三类:	
•	不对标签做任何保护
•	分词保留标签
•	分词bpe保留标签
带有复制机制的NMT-我们尝试在双语语料中标签的两端加上标记,形如’$copy<b>$copy’,然后将此三个部分看做一个整体,然后采取Baseline中的三种方法分别训练,然后进行测试,记录下评估结果
标签泛化-我们在上一个的基础上进行改进,我们将每个标签都进行泛化处理,即忽略标签的具体,仅记录其位置和编号(当然,也可以记录其是开始标签还是闭合标签).然后我们设定一个参数k,即我们只记录前k对标签的标号,例如’lable_l1’,并且我们把不成对的标签自身看作是一对,不再区分左右,以'lable_1'的形式进行记录.对于剩下的标签,我们就不再记录其标号,在翻译中采取同样的标记,然后按照顺序进行替换即可.相对于完全记录所有标签的位置,这种方法能够在当前紧张的计算资源下取得相对良好的效果.


分析谷歌翻译.谷歌作为一个此行业的领跑者,其对于带标签文本的翻译能给我们的研究带来一些启迪.然而其翻译应该是一种性能上和成本上的折中.在实际使用过程中也发现了一些缺陷.我们将会结合我们的需求吸取其先进之处.

对于数据集，我们从翻译公司得到了一些数据，但是相对于训练的模型来说并不够，所以我们要构造一些数据。
首先我们分析html的语法，分析出哪些标签经常出现在文本内部(此类称为L1)，哪些标签经常出现在文本两侧(此类称为L2)，哪些标签不成对出现(此类称为L3,不成对出现的往往出现在句子中间)。
然后我们找到比较高质量的双语语料。根据分词情况，对于源语言，在词之间随机插入L1或者L3类标签，在句子两侧随机插入L2标签。然后根据词对齐信息在相应的目标语言中也加入对应的标签。考虑到我们有比较多的双语语料，所以能构造出足够多的训练数据。
此外，还有公司给出的部分数据，我们作为测试数据。因为公司的数据可能带有一些偏好性。
为了提高部分特殊标签(比如某种标签几乎只会插在命名实体两侧)的翻译准确度，
考虑到命名实体识别算法已经比较成熟，我们可以针对这种性质构造出数据，使得模型对这种标签的识别性大大增强。

日程安排
week1
和学长沟通交流项目任务和解决方案，并对可行性进行评估，确定后续工作流程。
week2


评价指标
 1. 利用标签保留准确率，召回率，F1值等指标。就是统计原文和译文的标签数量。然后计算出保留的标签比率。
 2. 利用BLEU值进行估计。
 3. 人工限制评测条件。可以手动针对某个词条的上下文结果  估算其周围的标签结果是否予以保留。另外，还可以根据指定标签估算其在指定词汇上下文中出现时候的标签保留情况。




1. Introduction：介绍部分首先说明了带标签句子的用途 但我认为要说明 这部分工作往往需要依赖翻译公司进行完成  但其需要依赖机器翻译系统作为辅助进行翻译；另外，说明了目前NMT系统对于普通文本的翻译效果良好 但没有提出对于翻译带有标签文本的翻译效果情况；最后一段我认为没必要限制为翻译公司进行的工作；
2. Challenges  个人认为这部分内容需要进行补充  主要说明应该有几点：（1）标签多样性（2）标签出现的随机性
3. 采用标签泛化方式部分  处理按照标签对进行泛化之外，是否应该对不成对泛化方法进行写明 因为这也是值得进行尝试的一种方法


任务
对任务的认识

本质是反复尝试，尤其是在初始化方面

1. base line （基线，即最低限度，不加优化）:
    1.  保留标签，直接训练
    2.  分词保留标签（在分词的步骤保留完整标签，在子词切分的时候不保留），直接训练
    3.  分词bpe保留标签（子词切分的时候也保留标签），直接训练
2. 带有复制机制的NMT
    在标签两侧加上$copy  训练的结果是标记中间的内容需要保留
    可以与1 中的三种方法结合
3. 标签泛化
    1. 将标签本身泛化成￥lable 在一个句子中的前几个，考虑位置信息，然后后面的不考虑位置信息，全都是lable
    然后根据第一个整理出第二个，此步最好在分词，bpe的时候保留标签
    2。 对于成对出现的标签， lable_l1  ￥label_r1

4. 多组实验，分析google



以上结束


1. 数据构造
  1. wmt 18/19   900w 
  2. 怎么插入标签，插在哪  考虑  看网页源码，分析标签插入的概率或者习惯，
  3. 比如命名实体两侧，可以借鉴开源库，如果是命名实体两侧则简单了，专门构造这种数据进行训练
  4. 词对齐，词对齐信息进行标签插入
  5. 构造拟合数据集（更拟合翻译公司的习惯）


三。 模型评价


第一步，数据集构造，
1 。 训练（自己构造，调研哪些标签在命名实体周围，部分采用翻译公司，然后看公司的插入习惯，哪些词周围喜欢插入哪些标签） 校验（翻译公司） 测试




刚刚确认过了，翻译公司那边年前出来样本数据的几率很低，我这边也再催，但是我觉得我们先不要等他们了，先自己考虑构造数据集：
在数据集构造过程中，我主要考虑到的有以下几点规范，可能不全，希望各位能够予以补充：
1. 在标签集合中，各种标签在真实网页环境中习惯出现的位置，我认为在构造数据的时候，位置信息非常重要，例如：是否存在标签只能出现在句首句尾或者句中，某些标签是否可能出现大写的情况等等，也就是了解标签的使用特性，尽量保证我们构造的数据集能够最大程度地模拟真实网页标签结构
2. 在构造数据集的时候，需要考虑到各个标签样本构造的均衡性 ，尽量不要出现样本分布不均的情况（比如某个标签出现次数过少，或者标大多数只集中在句首部分或句尾部分等），保证模型能够学习到的情况更加全面
3. 在构造数据集的时候，需要考虑到单条句子最多出现的标签数量，也就是说，限制句子中的最大标签数，尽量不要让一条句子中出现过多的标签
4. 在构造标签句子的时候，一定要保证双语数据的对齐性，也就是说，应该先获取得到词对齐信息后，在进行双语数据的标签插入
关于词对齐方法可以使用fast_align方法，这方面我还是比较有经验的，有问题可以一起讨论

